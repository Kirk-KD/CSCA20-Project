{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirk-KD/CSCA20-Project/blob/master/CS_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculator Project\n",
        "\n",
        "## Features\n",
        "* **DONE** Define functions\n",
        "    * Example: f(x) = 2 * x + 3\n",
        "* **DONE** Graphing\n",
        "    * Matplotlib to be used to graph a function\n",
        "* Mapping certain strings to certain equations (customizable) (saving functions to CSV)\n",
        "* **DONE** Interpreter, parser, tokenizer, AST\n",
        "\n",
        "## Tokenizer\n",
        "* Takes in a string, converts it into a list of Tokens\n",
        "* Tokens are symbols or numbers or operators\n",
        "\n",
        "## Parser\n",
        "* Takes in a list of Tokens, builds an abstract syntax tree (AST)\n",
        "\n",
        "## AST\n",
        "* Consists of nodes, such as BinaryOp, UnaryOp, Expression, Statement etc\n",
        "* The structure of the tree defines the order of operations\n",
        "\n",
        "## Interpreter\n",
        "* Walks the AST, computing the result\n",
        "\n",
        "## Mapping equations\n",
        "* Separate mode that allows you to punch in a certain equation and map it to a specific string (like “a” or “plus2”)\n",
        "* Saved to a CSV file for organization and allows it to be called on any time\n"
      ],
      "metadata": {
        "id": "gP8Fa1sdBULF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammar\n",
        "\n",
        "```\n",
        "# Basics\n",
        "stmt     = expr | definition\n",
        "expr     = term { (\"+\" | \"-\") term }\n",
        "term     = unary { (\"*\" | \"/\") unary }\n",
        "unary    = (\"+\" | \"-\") unary | power\n",
        "power    = primary [ \"^\" power ]\n",
        "primary  = NUMBER | variable | func_call | \"(\" expr \")\"\n",
        "\n",
        "# Variables and functions\n",
        "definition = WORD [\"(\" \"x\" \")\"] \"=\" expr\n",
        "variable   = WORD\n",
        "func_call  = WORD \"(\" expr \")\"\n",
        "```"
      ],
      "metadata": {
        "id": "kgK9vuo-B294"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "lv_nXaOAYZAb"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "###############\n",
        "## Tokenizer ##\n",
        "###############\n",
        "\n",
        "class Tokenizer():\n",
        "    \"\"\"Handles initial processing of the input string.\"\"\"\n",
        "\n",
        "    def __init__(self, line: str):\n",
        "        self.line = line\n",
        "        self.index = 0\n",
        "\n",
        "    def make_tokens(self) -> 'list[Token]':\n",
        "        \"\"\"\n",
        "        Converts a string into a list of tokens by iteratively going over each\n",
        "        character. Exceptions will be raised when a character is unrecognized.\n",
        "        \"\"\"\n",
        "        tokens = []\n",
        "\n",
        "        SINGLE_CHAR_TOKENS = {\n",
        "            '(': TokenType.LPAREN,\n",
        "            ')': TokenType.RPAREN,\n",
        "            '+': TokenType.PLUS,\n",
        "            '-': TokenType.MINUS,\n",
        "            '*': TokenType.MUL,\n",
        "            '/': TokenType.DIV,\n",
        "            '^': TokenType.EXP,\n",
        "            '=': TokenType.EQ\n",
        "        }\n",
        "\n",
        "        while self.curr_char is not None:\n",
        "            c = self.curr_char  # short variable name\n",
        "\n",
        "            if c.isspace():\n",
        "                self._skip_whitespace()\n",
        "                continue\n",
        "\n",
        "            index = self.index\n",
        "            if c.isdigit():\n",
        "                num = self._make_number()\n",
        "                tokens.append(Token(TokenType.NUMBER, num, self, index))\n",
        "                continue\n",
        "            if c.isalpha():\n",
        "                word = self._make_word()\n",
        "                tokens.append(Token(TokenType.WORD, word, self, index))\n",
        "                continue\n",
        "            if c in SINGLE_CHAR_TOKENS:\n",
        "                token_type = SINGLE_CHAR_TOKENS[c]\n",
        "                tokens.append(Token(token_type, c, self, index))\n",
        "                self._advance()\n",
        "                continue\n",
        "\n",
        "            # unrecognized character\n",
        "            raise LocationalException(f\"Unrecognized character '{c}'\", self.line, index)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _make_number(self) -> float | int:\n",
        "        \"\"\"\n",
        "        Advances and makes a number. Handles decimals too. Raises exception when\n",
        "        a period is encountered twice.\n",
        "        \"\"\"\n",
        "        found_period = False\n",
        "        text = ''\n",
        "\n",
        "        while self.curr_char is not None and (self.curr_char.isdigit() or self.curr_char == '.'):\n",
        "            if self.curr_char == '.':\n",
        "                if not found_period:\n",
        "                    text += self.curr_char\n",
        "                    found_period = True\n",
        "                else:\n",
        "                    raise LocationalException('Unexpected period (.)', self.line, self.index)\n",
        "            else:\n",
        "                text += self.curr_char\n",
        "\n",
        "            self._advance()\n",
        "\n",
        "        return int(n) if (n := float(text)).is_integer() else n\n",
        "\n",
        "    def _make_word(self) -> str:\n",
        "        \"\"\"\n",
        "        Advances and makes a word (keyword, variable name, function name etc).\n",
        "        \"\"\"\n",
        "        text = ''\n",
        "        while self.curr_char is not None and self.curr_char.isalnum():\n",
        "            text += self.curr_char\n",
        "            self._advance()\n",
        "        return text\n",
        "\n",
        "    def _skip_whitespace(self):\n",
        "        \"\"\"\n",
        "        Keeps advancing until the current character is no longer a space.\n",
        "        \"\"\"\n",
        "        while self.curr_char is not None and self.curr_char.isspace():\n",
        "            self._advance()\n",
        "\n",
        "    def _advance(self):\n",
        "        \"\"\"\n",
        "        Increments the index by 1 if able.\n",
        "        \"\"\"\n",
        "        self.index += int(self.index < len(self.line))\n",
        "\n",
        "    @property\n",
        "    def curr_char(self) -> str | None:\n",
        "        \"\"\"\n",
        "        Retrieves the current character, or None.\n",
        "        \"\"\"\n",
        "        return self.line[self.index] if self.index < len(self.line) else None\n",
        "\n",
        "\n",
        "class TokenType(Enum):\n",
        "    NUMBER = 'Number'\n",
        "    WORD = 'Word'\n",
        "    LPAREN = '('\n",
        "    RPAREN = ')'\n",
        "    PLUS = '+'\n",
        "    MINUS = '-'\n",
        "    MUL = '*'\n",
        "    DIV = '/'\n",
        "    EXP = '^'\n",
        "    EQ = '='\n",
        "\n",
        "\n",
        "class Token():\n",
        "    def __init__(self, tok_type: TokenType, tok_val, tokenizer: Tokenizer = None, index: int = 0):\n",
        "        self.type = tok_type\n",
        "        self.value = tok_val\n",
        "        self.tokenizer = tokenizer\n",
        "        self.index = index\n",
        "\n",
        "    @property\n",
        "    def original_text(self) -> str:\n",
        "        return self.tokenizer.line if self.tokenizer is not None else '<none>'\n",
        "\n",
        "    @property\n",
        "    def length(self) -> int:\n",
        "        return len(str(self.value))\n",
        "\n",
        "    def throw(self, message: str):\n",
        "        raise LocationalException(message, self.original_text, self.index, self.length)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'Token({self.type}, {self.value})'\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "####################\n",
        "## Parser and AST ##\n",
        "####################\n",
        "\n",
        "class Parser():\n",
        "    def __init__(self, original_text: str, tokens: list[Token]):\n",
        "        self.original_text = original_text\n",
        "        self.tokens = tokens\n",
        "        self.index = 0\n",
        "\n",
        "    def parse(self) -> 'AST':\n",
        "        if len(self.tokens) == 0:\n",
        "            return AST()\n",
        "        stmt = self._stmt()\n",
        "        if self.curr_tok is not None:\n",
        "            self.curr_tok.throw('Unexpected token')\n",
        "        return stmt\n",
        "\n",
        "    def _stmt(self) -> 'Statement':\n",
        "        \"\"\"stmt = definition | expr\"\"\"\n",
        "        if any([token.type is TokenType.EQ for token in self.tokens]):\n",
        "            # found \"=\", treat it as a function or variable definition\n",
        "            return Statement(self._definition())\n",
        "        return Statement(self._expr())\n",
        "\n",
        "    def _definition(self) -> 'AST':\n",
        "        \"\"\"definition = WORD [\"(\" \"x\" \")\"] \"=\" expr\"\"\"\n",
        "        name = self.curr_tok\n",
        "        self._demand(TokenType.WORD)\n",
        "\n",
        "        if self.curr_tok is not None and self.curr_tok.type is TokenType.LPAREN:\n",
        "            # found \"(\", treat it as function definition\n",
        "            self._demand(TokenType.LPAREN)\n",
        "            x_token = self.curr_tok\n",
        "            self._demand(TokenType.WORD)\n",
        "            if x_token.value != 'x':\n",
        "                x_token.throw('Expected \"x\"')\n",
        "            self._demand(TokenType.RPAREN)\n",
        "            self._demand(TokenType.EQ)\n",
        "            is_func = True\n",
        "        else:\n",
        "            # treat it as variable definition\n",
        "            self._demand(TokenType.EQ)\n",
        "            is_func = False\n",
        "        expr = self._expr()\n",
        "        return Definition(name, expr, is_func)\n",
        "\n",
        "    def _expr(self) -> 'AST':\n",
        "        \"\"\"expr = term { ( \"+\" | \"-\" ) term }\"\"\"\n",
        "        node = self._term()\n",
        "        while self.curr_tok is not None and self.curr_tok.type in (TokenType.PLUS, TokenType.MINUS):\n",
        "            op = self.curr_tok\n",
        "            self._advance()\n",
        "            right = self._term()\n",
        "            node = BinOp(node, op, right)\n",
        "        return node\n",
        "\n",
        "    def _term(self) -> 'AST':\n",
        "        \"\"\"term = unary { (\"*\" | \"/\") unary }\"\"\"\n",
        "        node = self._unary()\n",
        "        while self.curr_tok is not None and self.curr_tok.type in (TokenType.MUL, TokenType.DIV):\n",
        "            op = self.curr_tok\n",
        "            self._advance()\n",
        "            right = self._unary()\n",
        "            node = BinOp(node, op, right)\n",
        "        return node\n",
        "\n",
        "    def _unary(self) -> 'AST':\n",
        "        \"\"\"unary = (\"+\" | \"-\") unary | power\"\"\"\n",
        "        if self.curr_tok is not None and self.curr_tok.type in (TokenType.PLUS, TokenType.MINUS):\n",
        "            sign_token = self.curr_tok\n",
        "            self._advance()\n",
        "            operand = self._unary()\n",
        "            return UnaryOp(sign_token, operand)\n",
        "        return self._power()\n",
        "\n",
        "    def _power(self) -> 'AST':\n",
        "        \"\"\"power = primary [ \"^\" power ]\"\"\"\n",
        "        node = self._primary()\n",
        "        if self.curr_tok is not None and self.curr_tok.type is TokenType.EXP:\n",
        "            op = self.curr_tok\n",
        "            self._advance()\n",
        "            right = self._power()\n",
        "            node = BinOp(node, op, right)\n",
        "        return node\n",
        "\n",
        "    def _primary(self) -> 'AST':\n",
        "        \"\"\"primary = NUMBER | variable | func_call | \"(\" expr \")\" \"\"\"\n",
        "        if self.curr_tok is None:\n",
        "            raise LocationalException(\n",
        "                'Unexpected end of input', self.original_text,\n",
        "                self.tokens[-1].index + self.tokens[-1].length\n",
        "            )\n",
        "\n",
        "        if self.curr_tok.type is TokenType.WORD:\n",
        "            word = self.curr_tok\n",
        "            self._advance()\n",
        "            if self.curr_tok is not None and self.curr_tok.type is TokenType.LPAREN:\n",
        "                self._demand(TokenType.LPAREN)\n",
        "                arg = self._expr()\n",
        "                self._demand(TokenType.RPAREN)\n",
        "                return FuncCall(word, arg)\n",
        "            return Variable(word)\n",
        "\n",
        "        if self.curr_tok.type is TokenType.NUMBER:\n",
        "            token = self.curr_tok\n",
        "            self._advance()\n",
        "            return Constant(token)\n",
        "\n",
        "        if self.curr_tok.type is TokenType.LPAREN:\n",
        "            self._demand(TokenType.LPAREN)\n",
        "            expr = self._expr()\n",
        "            self._demand(TokenType.RPAREN)\n",
        "            return expr\n",
        "\n",
        "        self.curr_tok.throw(f'Unexpected \"{self.curr_tok.value}\"')\n",
        "\n",
        "    def _demand(self, tok_type: TokenType):\n",
        "        \"\"\"Demand and consume a token of the required type, or throw an error.\"\"\"\n",
        "\n",
        "        if self.curr_tok is None:\n",
        "            raise LocationalException(\n",
        "                'Unexpected end of input',\n",
        "                self.original_text,\n",
        "                self.tokens[-1].index + self.tokens[-1].length\n",
        "            )\n",
        "\n",
        "        if self.curr_tok.type is not tok_type:\n",
        "            self.curr_tok.throw(f'Unexpected \"{self.curr_tok.value}\"')\n",
        "\n",
        "        self._advance()\n",
        "\n",
        "    def _advance(self):\n",
        "        # print(self.curr_tok)\n",
        "        self.index += int(self.index < len(self.tokens))\n",
        "\n",
        "    @property\n",
        "    def curr_tok(self) -> Token:\n",
        "        return self.tokens[self.index] if self.index < len(self.tokens) else None\n",
        "\n",
        "\n",
        "class AST():\n",
        "    \"\"\"Abstract base class for all nodes in the Abstract Syntax Tree.\"\"\"\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter'):\n",
        "        return None\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return str(self)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class Constant(AST):\n",
        "    \"\"\"AST node representing a numeric constant.\"\"\"\n",
        "\n",
        "    def __init__(self, token: Token):\n",
        "        self.token = token\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter') -> float:\n",
        "        if self.token.type is TokenType.NUMBER:\n",
        "            return self.token.value\n",
        "\n",
        "        self.token.throw('Invalid constant')\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'Constant({self.token})'\n",
        "\n",
        "\n",
        "class BinOp(AST):\n",
        "    \"\"\"AST node representing a binary operation (+, -, *, /, ^).\"\"\"\n",
        "\n",
        "    def __init__(self, left: AST, op: Token, right: AST):\n",
        "        self.left = left\n",
        "        self.op = op\n",
        "        self.right = right\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter') -> float:\n",
        "        match self.op.type:\n",
        "            case TokenType.PLUS:\n",
        "                return self.left.interpret(interpreter) + self.right.interpret(interpreter)\n",
        "            case TokenType.MINUS:\n",
        "                return self.left.interpret(interpreter) - self.right.interpret(interpreter)\n",
        "            case TokenType.MUL:\n",
        "                return self.left.interpret(interpreter) * self.right.interpret(interpreter)\n",
        "            case TokenType.DIV:\n",
        "                left = self.left.interpret(interpreter)\n",
        "                right = self.right.interpret(interpreter)\n",
        "                if right == 0:\n",
        "                    self.op.throw('Division by zero')\n",
        "                return self.left.interpret(interpreter) / self.right.interpret(interpreter)\n",
        "            case TokenType.EXP:\n",
        "                # use numpy to handle invalid exponentiation\n",
        "                with np.errstate(invalid='ignore'):\n",
        "                    return np.power(self.left.interpret(interpreter),\n",
        "                                    self.right.interpret(interpreter),\n",
        "                                    dtype=float)\n",
        "        self.op.throw('Invalid operator')\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'BinOp({self.left} {self.op} {self.right})'\n",
        "\n",
        "\n",
        "class UnaryOp(AST):\n",
        "    \"\"\"AST node representing a unary operation (+ or - before an expression).\"\"\"\n",
        "\n",
        "    def __init__(self, op: Token, right: AST):\n",
        "        self.op = op\n",
        "        self.right = right\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter') -> float:\n",
        "        if self.op.type is TokenType.PLUS:\n",
        "            return self.right.interpret(interpreter)\n",
        "        elif self.op.type is TokenType.MINUS:\n",
        "            return -self.right.interpret(interpreter)\n",
        "        self.op.throw('Invalid operator')\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'UnaryOp({self.op}{self.right})'\n",
        "\n",
        "\n",
        "class Definition(AST):\n",
        "    \"\"\"AST node representing a variable or function definition.\"\"\"\n",
        "\n",
        "    def __init__(self, name: Token, expr: AST, is_func: bool):\n",
        "        self.name = name\n",
        "        self.expr = expr\n",
        "        self.is_func = is_func\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter'):\n",
        "        # store AST node if defining function, otherwise store result\n",
        "        interpreter.symbols[self.name.value] = self.expr if self.is_func \\\n",
        "            else self.expr.interpret(interpreter)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'Definition({self.name}, {self.expr}, {\"func\" if self.is_func else \"var\"})'\n",
        "\n",
        "\n",
        "class Variable(AST):\n",
        "    \"\"\"AST node representing a variable reference.\"\"\"\n",
        "\n",
        "    def __init__(self, name: Token):\n",
        "        self.name = name\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter'):\n",
        "        if self.name.value not in interpreter.symbols:\n",
        "            self.name.throw('Undefined variable')\n",
        "        return interpreter.symbols[self.name.value]\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'Variable({self.name})'\n",
        "\n",
        "\n",
        "class FuncCall(AST):\n",
        "    \"\"\"AST node representing a function call.\"\"\"\n",
        "\n",
        "    def __init__(self, name: Token, arg: AST):\n",
        "        self.name = name\n",
        "        self.arg = arg\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter'):\n",
        "        if self.name.value not in interpreter.symbols:\n",
        "            self.name.throw('Undefined function')\n",
        "\n",
        "        arg_result = self.arg.interpret(interpreter)\n",
        "        old_x = interpreter.symbols['x'] if 'x' in interpreter.symbols else None\n",
        "        interpreter.symbols['x'] = arg_result\n",
        "\n",
        "        func_ast = interpreter.symbols[self.name.value]\n",
        "        if not isinstance(func_ast, AST):\n",
        "            self.name.throw('Not a function')\n",
        "\n",
        "        func_result = func_ast.interpret(interpreter)\n",
        "        if old_x is not None:\n",
        "            interpreter.symbols['x'] = old_x\n",
        "        else:\n",
        "            interpreter.symbols.pop('x', None)\n",
        "\n",
        "        return func_result\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'FuncCall({self.name}, {self.arg})'\n",
        "\n",
        "\n",
        "class Statement(AST):\n",
        "    \"\"\"AST node representing a complete statement (one line of input).\"\"\"\n",
        "\n",
        "    def __init__(self, node: AST):\n",
        "        self.node = node\n",
        "\n",
        "    def interpret(self, interpreter: 'Interpreter') -> float | None:\n",
        "        return self.node.interpret(interpreter)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'Statement({self.node})'\n",
        "\n",
        "\n",
        "#################\n",
        "## Interpreter ##\n",
        "#################\n",
        "\n",
        "class Interpreter():\n",
        "    \"\"\"Evaluates AST nodes and maintains symbol table for variables and functions.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.flag_exit = False\n",
        "        self.symbols: dict[str, float | AST] = {}\n",
        "\n",
        "    def exit(self):\n",
        "        self.flag_exit = True\n",
        "\n",
        "    def interpret(self, root: AST) -> float | None:\n",
        "        return root.interpret(self)\n",
        "\n",
        "\n",
        "################\n",
        "## Exceptions ##\n",
        "################\n",
        "\n",
        "class LocationalException(Exception):\n",
        "    def __init__(self, message: str, text: str, index: int, length: int = 1):\n",
        "        self.message = message\n",
        "        self.text = text\n",
        "        self.index = index\n",
        "        self.length = length\n",
        "\n",
        "        msg = f'''\n",
        "ERROR: {self.text}\n",
        "       {self._get_error_highlight()}\n",
        "{self.message}'''\n",
        "        super().__init__(msg)\n",
        "\n",
        "    def _get_error_highlight(self) -> str:\n",
        "        return ' ' * self.index + '^' * self.length\n",
        "\n",
        "\n",
        "################\n",
        "## Calculator ##\n",
        "################\n",
        "\n",
        "class Calculator():\n",
        "    def __init__(self):\n",
        "        self.interpreter = Interpreter()\n",
        "        self.commands = {\n",
        "            'EXIT': self._exit,\n",
        "            'PLOT': self._plot\n",
        "        }\n",
        "\n",
        "    def _exit(self, args: str):\n",
        "        \"\"\"Syntax: EXIT\"\"\"\n",
        "        raise SystemExit()\n",
        "\n",
        "    def _plot(self, args: str):\n",
        "        \"\"\"Syntax: PLOT <function_name> [<x_from=-10>, <x_to=10>]\n",
        "\n",
        "        Plots the graph of the specified function using matplotlib without\n",
        "        blocking the main thread. The range for the x axis is [-10, 10] by\n",
        "        default.\n",
        "        \"\"\"\n",
        "        default_x_from, default_x_to = -10, 10\n",
        "        parts = [arg.strip() for arg in args.split(',')]\n",
        "\n",
        "        try:\n",
        "            if len(args) == 0:\n",
        "                raise ValueError\n",
        "\n",
        "            func_name = parts[0].strip()\n",
        "            x_min = float(parts[1].strip()) if len(parts) > 1 else default_x_from\n",
        "            x_max = float(parts[2].strip()) if len(parts) > 2 else default_x_to\n",
        "        except (ValueError, IndexError):\n",
        "            raise Exception('Syntax error. Correct usage:'\n",
        "                '\\n  PLOT <function_name> [<x_from=-10>, <x_to=10>]')\n",
        "\n",
        "        func_ast = self.interpreter.symbols.get(func_name)\n",
        "        if func_ast is None or not isinstance(func_ast, AST):\n",
        "            raise Exception(f'\"{func_name}\" is not a function name. Correct usage:'\n",
        "                '\\n  PLOT <function_name> [<x_from=-10>, <x_to=10>]')\n",
        "\n",
        "        x_vals = np.linspace(x_min, x_max, 500)\n",
        "        y_vals = []\n",
        "\n",
        "        old_x = self.interpreter.symbols.get('x')\n",
        "\n",
        "        for x in x_vals:\n",
        "            self.interpreter.symbols['x'] = x\n",
        "            try:\n",
        "                y = func_ast.interpret(self.interpreter)\n",
        "            except Exception:\n",
        "                y = np.nan\n",
        "            y_vals.append(y)\n",
        "\n",
        "        if old_x is not None:\n",
        "            self.interpreter.symbols['x'] = old_x\n",
        "        else:\n",
        "            self.interpreter.symbols.pop('x', None)\n",
        "\n",
        "        plt.plot(x_vals, y_vals)\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel(f'{func_name}(x)')\n",
        "        plt.title(f'Graph of {func_name}(x), x ∈ [{x_min}, {x_max}]')\n",
        "        plt.grid(True)\n",
        "        plt.show(block=False)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"The read-eval-print loop.\n",
        "\n",
        "        Commands are identified by the first word of the line, and handled\n",
        "        seperately from a normal evaluation.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            while True:\n",
        "                try:\n",
        "                    line = input('\\n>>> ').strip()\n",
        "                    if not line:\n",
        "                        continue\n",
        "\n",
        "                    for cmd, handler in self.commands.items():\n",
        "                        if line.startswith(cmd):\n",
        "                            handler(line[len(cmd):].strip())\n",
        "                            break\n",
        "                    else:\n",
        "                        tokenizer = Tokenizer(line)\n",
        "                        tokens = tokenizer.make_tokens()\n",
        "                        parser = Parser(line, tokens)\n",
        "                        ast_root = parser.parse()\n",
        "                        result = self.interpreter.interpret(ast_root)\n",
        "                        if isinstance(result, float):\n",
        "                            print(int(result) if result.is_integer() else result)\n",
        "                        elif isinstance(result, int):\n",
        "                            print(result)\n",
        "                except SystemExit:\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "        except KeyboardInterrupt:\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "wXhaZMeFLom8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tt(tokens: list[Token]):\n",
        "    \"\"\"Utilify function for ease of unit tests.\"\"\"\n",
        "    return [(t.type, t.value) for t in tokens]\n",
        "\n",
        "\n",
        "class TestTokenizer(unittest.TestCase):\n",
        "    def test_all_operators_and_parens(self):\n",
        "        t = Tokenizer('()+-*/^')\n",
        "        tokens = t.make_tokens()\n",
        "        expected = [\n",
        "            (TokenType.LPAREN, '('),\n",
        "            (TokenType.RPAREN, ')'),\n",
        "            (TokenType.PLUS, '+'),\n",
        "            (TokenType.MINUS, '-'),\n",
        "            (TokenType.MUL, '*'),\n",
        "            (TokenType.DIV, '/'),\n",
        "            (TokenType.EXP, '^'),\n",
        "        ]\n",
        "        self.assertEqual(tt(tokens), expected)\n",
        "\n",
        "    def test_sequence_with_spaces(self):\n",
        "        t = Tokenizer('(  +   \\n\\r\\t)')\n",
        "        tokens = t.make_tokens()\n",
        "        expected = [\n",
        "            (TokenType.LPAREN, '('),\n",
        "            (TokenType.PLUS, '+'),\n",
        "            (TokenType.RPAREN, ')'),\n",
        "        ]\n",
        "        self.assertEqual(tt(tokens), expected)\n",
        "\n",
        "    def test_numbers(self):\n",
        "        t = Tokenizer('1 123 3.1415')\n",
        "        tokens = t.make_tokens()\n",
        "        expected = [\n",
        "            (TokenType.NUMBER, 1),\n",
        "            (TokenType.NUMBER, 123),\n",
        "            (TokenType.NUMBER, 3.1415)\n",
        "        ]\n",
        "        self.assertEqual(tt(tokens), expected)\n",
        "\n",
        "    def test_mixed_expression(self):\n",
        "        t = Tokenizer('1+2*(3-4)^5/6')\n",
        "        tokens = t.make_tokens()\n",
        "        expected = [\n",
        "            (TokenType.NUMBER, 1),\n",
        "            (TokenType.PLUS, '+'),\n",
        "            (TokenType.NUMBER, 2),\n",
        "            (TokenType.MUL, '*'),\n",
        "            (TokenType.LPAREN, '('),\n",
        "            (TokenType.NUMBER, 3),\n",
        "            (TokenType.MINUS, '-'),\n",
        "            (TokenType.NUMBER, 4),\n",
        "            (TokenType.RPAREN, ')'),\n",
        "            (TokenType.EXP, '^'),\n",
        "            (TokenType.NUMBER, 5),\n",
        "            (TokenType.DIV, '/'),\n",
        "            (TokenType.NUMBER, 6),\n",
        "        ]\n",
        "        self.assertEqual(tt(tokens), expected)\n",
        "\n",
        "    def test_empty(self):\n",
        "        t = Tokenizer('')\n",
        "        tokens = t.make_tokens()\n",
        "        self.assertEqual(tokens, [])\n",
        "\n",
        "    def test_unrecognized_character(self):\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            Tokenizer('1 + @').make_tokens()\n",
        "        self.assertIn(\"Unrecognized character '@'\", str(cm.exception))\n",
        "\n",
        "    def test_malformed_number(self):\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            Tokenizer('1.2.3').make_tokens()\n",
        "        msg = str(cm.exception)\n",
        "        self.assertIn('Unexpected period', msg)\n",
        "        self.assertIn('1.2.3', msg)\n",
        "        self.assertIn('^', msg)\n",
        "\n",
        "\n",
        "class TestInterpreter(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    The bulk of the testing would be done here, at a high level.\n",
        "    \"\"\"\n",
        "\n",
        "    def _test_interpretation(self, expression: str, expected_result: float):\n",
        "        \"\"\"Just a helper private method to do tests easier.\"\"\"\n",
        "        tokenizer = Tokenizer(expression)\n",
        "        tokens = tokenizer.make_tokens()\n",
        "        parser = Parser(expression, tokens)\n",
        "        root = parser.parse()\n",
        "        interpreter = Interpreter()\n",
        "        self.assertAlmostEqual(interpreter.interpret(root), expected_result, places=7)\n",
        "\n",
        "    def _test_definition(self, expression: str, var_name: str, expected_value: float | AST, is_func: bool = False):\n",
        "        tokenizer = Tokenizer(expression)\n",
        "        tokens = tokenizer.make_tokens()\n",
        "        parser = Parser(expression, tokens)\n",
        "        root = parser.parse()\n",
        "        interpreter = Interpreter()\n",
        "        root.interpret(interpreter)\n",
        "        if is_func:\n",
        "            # store the AST, check the type and then its string representation\n",
        "            self.assertIsInstance(interpreter.symbols.get(var_name), AST)\n",
        "            self.assertEqual(str(interpreter.symbols[var_name]), str(expected_value))\n",
        "        else:\n",
        "            self.assertAlmostEqual(interpreter.symbols.get(var_name), expected_value, places=7)\n",
        "\n",
        "    def _test_func_call(self, setup_expressions: list[str], call_expression: str, expected_result: float):\n",
        "        interpreter = Interpreter()\n",
        "        for setup_expr in setup_expressions:\n",
        "            tokenizer = Tokenizer(setup_expr)\n",
        "            tokens = tokenizer.make_tokens()\n",
        "            parser = Parser(setup_expr, tokens)\n",
        "            root = parser.parse()\n",
        "            root.interpret(interpreter)\n",
        "\n",
        "        tokenizer_call = Tokenizer(call_expression)\n",
        "        tokens_call = tokenizer_call.make_tokens()\n",
        "        parser_call = Parser(call_expression, tokens_call)\n",
        "        root_call = parser_call.parse()\n",
        "        self.assertAlmostEqual(root_call.interpret(interpreter), expected_result, places=7)\n",
        "\n",
        "    # Arithmatics\n",
        "\n",
        "    def test_number(self):\n",
        "        self._test_interpretation(\"5\", 5.0)\n",
        "\n",
        "    def test_plus_minus(self):\n",
        "        self._test_interpretation(\"1 + 2 - 3\", 0.0)\n",
        "        self._test_interpretation(\"10 - 20\", -10.0)\n",
        "\n",
        "    def test_mul_div(self):\n",
        "        self._test_interpretation(\"6 * 2 / 3\", 4.0)\n",
        "        self._test_interpretation(\"10 / 2 * 5\", 25.0)\n",
        "\n",
        "    def test_exponents(self):\n",
        "        self._test_interpretation(\"2 ^ 3\", 8.0)\n",
        "        self._test_interpretation(\"2 ^ 3 ^ 2\", 512.0)  # test right-association\n",
        "        self._test_interpretation(\"2 ^ 2 ^ 3\", 256.0)  # test right-association\n",
        "\n",
        "    def test_mixed_ops(self):\n",
        "        self._test_interpretation(\"1 + 2 * 3\", 7.0)\n",
        "        self._test_interpretation(\"10 - 4 / 2\", 8.0)\n",
        "        self._test_interpretation(\"2 + 3 * 4 ^ 2\", 50.0)\n",
        "        self._test_interpretation(\"10 / 2 + 3 * 4\", 17.0)\n",
        "\n",
        "    def test_parentheses(self):\n",
        "        self._test_interpretation(\"(1 + 2) * 3\", 9.0)\n",
        "        self._test_interpretation(\"10 / (5 - 3)\", 5.0)\n",
        "        self._test_interpretation(\"(2 + 3) ^ 2\", 25.0)\n",
        "        self._test_interpretation(\"((1 + 1) * 2) ^ 3\", 64.0)\n",
        "\n",
        "    def test_unary_ops(self):\n",
        "        self._test_interpretation(\"+5\", 5.0)\n",
        "        self._test_interpretation(\"-5\", -5.0)\n",
        "        self._test_interpretation(\"-(2 + 3)\", -5.0)\n",
        "        self._test_interpretation(\"5 + -2\", 3.0)\n",
        "        self._test_interpretation(\"-(-5)\", 5.0)\n",
        "        self._test_interpretation(\"-3 * 4\", -12.0)\n",
        "        self._test_interpretation(\"(-3)^2\", 9.0)\n",
        "        self._test_interpretation(\"-3^2\", -9.0)\n",
        "\n",
        "    def test_complex_expression(self):\n",
        "        self._test_interpretation(\"1 + 2 * (3 - 4) ^ 5 / 6 - (-1)\", 1.6666666666666665)\n",
        "        self._test_interpretation(\"10 + (2 * 3 - 4) / 2 ^ 2\", 10.5)\n",
        "\n",
        "    def test_empty(self):\n",
        "        tokenizer = Tokenizer('')\n",
        "        tokens = tokenizer.make_tokens()\n",
        "        parser = Parser('', tokens)\n",
        "        root = parser.parse()\n",
        "        interpreter = Interpreter()\n",
        "        self.assertIsNone(interpreter.interpret(root))\n",
        "\n",
        "    def test_div_by_zero(self):\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation(\"10 / (5 - 5)\", 0.0)\n",
        "        self.assertIn('Division by zero', str(cm.exception))\n",
        "\n",
        "    # Variables and functions\n",
        "\n",
        "    def test_definition(self):\n",
        "        self._test_definition('x=1', 'x', 1)\n",
        "        self._test_definition('a=1+2+3+4', 'a', 10)\n",
        "\n",
        "        self._test_definition('f(x)=2*x', 'f', BinOp(Constant(Token(TokenType.NUMBER, 2)), Token(TokenType.MUL, '*'), Variable(Token(TokenType.WORD, 'x'))), True)\n",
        "        self._test_definition('g(x)=0', 'g', Constant(Token(TokenType.NUMBER, 0)), True)\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation('x', None)\n",
        "        self.assertIn('Undefined variable', str(cm.exception))\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation('f(a) = 10', None)\n",
        "        self.assertIn('Expected \"x\"', str(cm.exception))\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation('a=1=2', None)\n",
        "\n",
        "    def test_function_call(self):\n",
        "        self._test_func_call(['g(x)=10*x', 'f(x)=2*x'], 'f(g(1))', 20)\n",
        "        self._test_func_call(['f(x)=2*a*x', 'a=12'], 'f(0.5)', 12)\n",
        "        self._test_func_call(['f(x)=2*x^2 + 3*x - 5.5', 'x = 0'], 'f(x)', -5.5)\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation('f(1)', None)\n",
        "        self.assertIn('Undefined function', str(cm.exception))\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_interpretation('f(1)', None)\n",
        "        self.assertIn('Undefined function', str(cm.exception))\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_func_call(['f=10'], 'f(0)', None)\n",
        "        self.assertIn('Not a function', str(cm.exception))\n",
        "\n",
        "        with self.assertRaises(LocationalException) as cm:\n",
        "            self._test_func_call(['f(x)=2*x', 'f=10'], 'f(0)', None)\n",
        "        self.assertIn('Not a function', str(cm.exception))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbRIsekLpo0",
        "outputId": "14971647-a7db-4486-9a42-e1b2233af72a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...................\n",
            "----------------------------------------------------------------------\n",
            "Ran 19 tests in 0.021s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entry"
      ],
      "metadata": {
        "id": "-SPjWQUOZ8KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    calculator = Calculator()\n",
        "    calculator.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j97FiGK5Mvxb",
        "outputId": "929e6db5-21e0-4bde-d1eb-c43c44ec4a1f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> 3a\n",
            "\n",
            "ERROR: 3a\n",
            "        ^\n",
            "Unexpected token\n",
            "\n",
            ">>> 3a=12\n",
            "\n",
            "ERROR: 3a=12\n",
            "       ^\n",
            "Unexpected \"3\"\n",
            "\n",
            ">>> a3=123\n",
            "\n",
            ">>> a1=120\n",
            "\n",
            ">>> a2=11\n",
            "\n",
            ">>> a1*a2*a3\n",
            "162360\n"
          ]
        }
      ]
    }
  ]
}